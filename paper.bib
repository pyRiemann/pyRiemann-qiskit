
@article{barachant_multiclass_2012,
	title = {Multiclass brain-computer interface classification by {Riemannian} geometry},
	volume = {59},
	issn = {1558-2531},
	doi = {10.1109/TBME.2011.2172210},
	abstract = {This paper presents a new classification framework for brain-computer interface (BCI) based on motor imagery. This framework involves the concept of Riemannian geometry in the manifold of covariance matrices. The main idea is to use spatial covariance matrices as EEG signal descriptors and to rely on Riemannian geometry to directly classify these matrices using the topology of the manifold of symmetric and positive definite (SPD) matrices. This framework allows to extract the spatial information contained in EEG signals without using spatial filtering. Two methods are proposed and compared with a reference method [multiclass Common Spatial Pattern (CSP) and Linear Discriminant Analysis (LDA)] on the multiclass dataset IIa from the BCI Competition IV. The first method, named minimum distance to Riemannian mean (MDRM), is an implementation of the minimum distance to mean (MDM) classification algorithm using Riemannian distance and Riemannian mean. This simple method shows comparable results with the reference method. The second method, named tangent space LDA (TSLDA), maps the covariance matrices onto the Riemannian tangent space where matrices can be vectorized and treated as Euclidean objects. Then, a variable selection procedure is applied in order to decrease dimensionality and a classification by LDA is performed. This latter method outperforms the reference method increasing the mean classification accuracy from 65.1\% to 70.2\%.},
	language = {eng},
	number = {4},
	journal = {IEEE transactions on bio-medical engineering},
	author = {Barachant, Alexandre and Bonnet, Stéphane and Congedo, Marco and Jutten, Christian},
	year = {2012},
	keywords = {Electroencephalography, Humans, User-Computer Interface, Evoked Potentials, Algorithms, Automated, Imagination, Motor, Motor Cortex, Movement, Pattern Recognition, Reproducibility of Results, Sensitivity and Specificity},
	pages = {920--928},
}

@misc{abraham_qiskit_2019,
	title = {Qiskit: {An} {Open}-source {Framework} for {Quantum} {Computing}},
	shorttitle = {Qiskit},
	urldate = {2021-03-11},
	publisher = {Zenodo},
	author = {Abraham, Héctor and {AduOffei} and Agarwal, Rochisha and Akhalwaya, Ismail Yunus and Aleksandrowicz, Gadi and Alexander, Thomas and Arbel, Eli and Asfaw, Abraham and Azaustre, Carlos and {AzizNgoueya} and Bansal, Aman and Barkoutsos, Panagiotis and Barron, George and Bello, Luciano and Ben-Haim, Yael and Bevenius, Daniel and Bishop, Lev S. and Bolos, Sorin and Bosch, Samuel and Bravyi, Sergey and Bucher, David and Burov, Artemiy and Cabrera, Fran and Calpin, Padraic and Capelluto, Lauren and Carballo, Jorge and Carrascal, Ginés and Chen, Adrian and Chen, Chun-Fu and Chen, Edward and Chen, Jielun (Chris) and Chen, Richard and Chow, Jerry M. and Churchill, Spencer and Claus, Christian and Clauss, Christian and Cocking, Romilly and Cross, Abigail J. and Cross, Andrew W. and Cross, Simon and Cruz-Benito, Juan and Culver, Chris and Córcoles-Gonzales, Antonio D. and Dague, Sean and Dandachi, Tareq El and Daniels, Marcus and Dartiailh, Matthieu and {DavideFrr} and Davila, Abdón Rodríguez and Dekusar, Anton and Ding, Delton and Doi, Jun and Drechsler, Eric and {Drew} and Dumitrescu, Eugene and Dumon, Karel and Duran, Ivan and EL-Safty, Kareem and Eastman, Eric and Eendebak, Pieter and Egger, Daniel and Everitt, Mark and Fernández, Paco Martín and Ferrera, Axel Hernández and Fouilland, Romain and {FranckChevallier} and Frisch, Albert and Fuhrer, Andreas and GEORGE, MELVIN and Gacon, Julien and Gago, Borja Godoy and Gambella, Claudio and Gambetta, Jay M. and Gammanpila, Adhisha and Garcia, Luis and Garion, Shelly and Gilliam, Austin and Giridharan, Aditya and Gomez-Mosquera, Juan and González, Salvador de la Puente and Gorzinski, Jesse and Gould, Ian and Greenberg, Donny and Grinko, Dmitry and Guan, Wen and Gunnels, John A. and Haglund, Mikael and Haide, Isabel and Hamamura, Ikko and Hamido, Omar Costa and Havlicek, Vojtech and Hellmers, Joe and Herok, {\textbackslash}Lukasz and Hillmich, Stefan and Horii, Hiroshi and Howington, Connor and Hu, Shaohan and Hu, Wei and Huisman, Rolf and Imai, Haruki and Imamichi, Takashi and Ishizaki, Kazuaki and Iten, Raban and Itoko, Toshinari and {JamesSeaward} and Javadi, Ali and Javadi-Abhari, Ali and {Jessica} and Jivrajani, Madhav and Johns, Kiran and {Jonathan-Shoemaker} and Kachmann, Tal and Kanazawa, Naoki and {Kang-Bae} and Karazeev, Anton and Kassebaum, Paul and King, Spencer and {Knabberjoe} and Kobayashi, Yuri and Kovyrshin, Arseny and Krishnakumar, Rajiv and Krishnan, Vivek and Krsulich, Kevin and Kus, Gawel and LaRose, Ryan and Lacal, Enrique and Lambert, Raphaël and Lapeyre, John and Latone, Joe and Lawrence, Scott and Lee, Christina and Li, Gushu and Liu, Dennis and Liu, Peng and Maeng, Yunho and Malyshev, Aleksei and Manela, Joshua and Marecek, Jakub and Marques, Manoel and Maslov, Dmitri and Mathews, Dolph and Matsuo, Atsushi and McClure, Douglas T. and McGarry, Cameron and McKay, David and McPherson, Dan and Meesala, Srujan and Metcalfe, Thomas and Mevissen, Martin and Mezzacapo, Antonio and Midha, Rohit and Minev, Zlatko and Mitchell, Abby and Moll, Nikolaj and Mooring, Michael Duane and Morales, Renier and Moran, Niall and {MrF} and Murali, Prakash and Müggenburg, Jan and Nadlinger, David and Nakanishi, Ken and Nannicini, Giacomo and Nation, Paul and Navarro, Edwin and Naveh, Yehuda and Neagle, Scott Wyman and Neuweiler, Patrick and Niroula, Pradeep and Norlen, Hassi and O'Riordan, Lee James and Ogunbayo, Oluwatobi and Ollitrault, Pauline and Oud, Steven and Padilha, Dan and Paik, Hanhee and Pang, Yuchen and Perriello, Simone and Phan, Anna and Piro, Francesco and Pistoia, Marco and Piveteau, Christophe and Pozas-iKerstjens, Alejandro and Prutyanov, Viktor and Puzzuoli, Daniel and Pérez, Jesús and {Quintiii} and Rahman, Rafey Iqbal and Raja, Arun and Ramagiri, Nipun and Rao, Anirudh and Raymond, Rudy and Redondo, Rafael Martín-Cuevas and Reuter, Max and Rice, Julia and Rodríguez, Diego M. and {RohithKarur} and Rossmannek, Max and Ryu, Mingi and SAPV, Tharrmashastha and {SamFerracin} and Sandberg, Martin and Sapra, Ritvik and Sargsyan, Hayk and Sarkar, Aniruddha and Sathaye, Ninad and Schmitt, Bruno and Schnabel, Chris and Schoenfeld, Zachary and Scholten, Travis L. and Schoute, Eddie and Schwarm, Joachim and Sertage, Ismael Faro and Setia, Kanav and Shammah, Nathan and Shi, Yunong and Silva, Adenilton and Simonetto, Andrea and Singstock, Nick and Siraichi, Yukio and Sitdikov, Iskandar and Sivarajah, Seyon and Sletfjerding, Magnus Berg and Smolin, John A. and Soeken, Mathias and Sokolov, Igor Olegovich and {SooluThomas} and {Starfish} and Steenken, Dominik and Stypulkoski, Matt and Sun, Shaojun and Sung, Kevin J. and Takahashi, Hitomi and Tavernelli, Ivano and Taylor, Charles and Taylour, Pete and Thomas, Soolu and Tillet, Mathieu and Tod, Maddy and Tomasik, Miroslav and Torre, Enrique de la and Trabing, Kenso and Treinish, Matthew and {TrishaPe} and Turner, Wes and Vaknin, Yotam and Valcarce, Carmen Recio and Varchon, Francois and Vazquez, Almudena Carrera and Villar, Victor and Vogt-Lee, Desiree and Vuillot, Christophe and Weaver, James and Wieczorek, Rafal and Wildstrom, Jonathan A. and Winston, Erick and Woehr, Jack J. and Woerner, Stefan and Woo, Ryan and Wood, Christopher J. and Wood, Ryan and Wood, Stephen and Wood, Steve and Wootton, James and Yeralin, Daniyar and Yonge-Mallo, David and Young, Richard and Yu, Jessie and Zachow, Christopher and Zdanski, Laura and Zhang, Helena and Zoufal, Christa and {Zoufalc} and {a-kapila} and {a-matsuo} and {bcamorrison} and {brandhsn} and {chlorophyll-zz} and {dekel.meirom} and {dekool} and {dime10} and {drholmie} and {dtrenev} and {ehchen} and {elfrocampeador} and {faisaldebouni} and {fanizzamarco} and {gadial} and {gruu} and {hhorii} and {hykavitha} and {jagunther} and {jliu45} and {kanejess} and {klinvill} and {kurarrr} and {lerongil} and {ma5x} and {merav-aharoni} and {michelle4654} and {ordmoj} and {rmoyard} and {saswati-qiskit} and {sethmerkel} and {strickroman} and {sumitpuri} and {tigerjack} and {toural} and {vvilpas} and {welien} and {willhbang} and {yang.luh} and {yotamvakninibm} and Čepulkovskis, Mantas},
	year = {2019},
	doi = {10.5281/zenodo.2562110},
}

@article{blance_quantum_2021,
	title = {Quantum machine learning for particle physics using a variational quantum classifier},
	volume = {2021},
	issn = {1029-8479},
	url = {https://doi.org/10.1007/JHEP02(2021)212},
	doi = {10.1007/JHEP02(2021)212},
	abstract = {Quantum machine learning aims to release the prowess of quantum computing to improve machine learning methods. By combining quantum computing methods with classical neural network techniques we aim to foster an increase of performance in solving classification problems. Our algorithm is designed for existing and near-term quantum devices. We propose a novel hybrid variational quantum classifier that combines the quantum gradient descent method with steepest gradient descent to optimise the parameters of the network. By applying this algorithm to a resonance search in di-top final states, we find that this method has a better learning outcome than a classical neural network or a quantum machine learning method trained with a non-quantum optimisation method. The classifiers ability to be trained on small amounts of data indicates its benefits in data-driven classification problems.},
	language = {en},
	number = {2},
	urldate = {2021-09-20},
	journal = {Journal of High Energy Physics},
	author = {Blance, Andrew and Spannowsky, Michael},
	month = feb,
	year = {2021},
	pages = {212},
	file = {Springer Full Text PDF:C\:\\Users\\GregoireCattan\\Zotero\\storage\\6JGGAXJY\\Blance and Spannowsky - 2021 - Quantum machine learning for particle physics usin.pdf:application/pdf},
}

@article{havlicek_supervised_2019,
	title = {Supervised learning with quantum-enhanced feature spaces},
	volume = {567},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-019-0980-2},
	doi = {10.1038/s41586-019-0980-2},
	abstract = {Machine learning and quantum computing are two technologies that each have the potential to alter how computation is performed to address previously untenable problems. Kernel methods for machine learning are ubiquitous in pattern recognition, with support vector machines (SVMs) being the best known method for classification problems. However, there are limitations to the successful solution to such classification problems when the feature space becomes large, and the kernel functions become computationally expensive to estimate. A core element in the computational speed-ups enabled by quantum algorithms is the exploitation of an exponentially large quantum state space through controllable entanglement and interference. Here we propose and experimentally implement two quantum algorithms on a superconducting processor. A key component in both methods is the use of the quantum state space as feature space. The use of a quantum-enhanced feature space that is only efficiently accessible on a quantum computer provides a possible path to quantum advantage. The algorithms solve a problem of supervised learning: the construction of a classifier. One method, the quantum variational classifier, uses a variational quantum circuit1,2 to classify the data in a way similar to the method of conventional SVMs. The other method, a quantum kernel estimator, estimates the kernel function on the quantum computer and optimizes a classical SVM. The two methods provide tools for exploring the applications of noisy intermediate-scale quantum computers3 to machine learning.},
	language = {en},
	number = {7747},
	urldate = {2021-09-21},
	journal = {Nature},
	author = {Havlíček, Vojtěch and Córcoles, Antonio D. and Temme, Kristan and Harrow, Aram W. and Kandala, Abhinav and Chow, Jerry M. and Gambetta, Jay M.},
	month = mar,
	year = {2019},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 7747
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Computer science;Quantum information;Quantum simulation;Qubits;Statistics
Subject\_term\_id: computer-science;quantum-information;quantum-simulation;qubits;statistics},
	pages = {209--212},
	file = {Snapshot:C\:\\Users\\GregoireCattan\\Zotero\\storage\\5GQ62E83\\s41586-019-0980-2.html:text/html;Submitted Version:C\:\\Users\\GregoireCattan\\Zotero\\storage\\T36G3TF5\\Havlíček et al. - 2019 - Supervised learning with quantum-enhanced feature .pdf:application/pdf},
}

@article{zhao_convex_2019,
	title = {Convex {Class} {Model} on {Symmetric} {Positive} {Definite} {Manifolds}},
	abstract = {The effectiveness of Symmetric Positive Definite (SPD) manifold features has been proven in various computer vision tasks. However, due to the non-Euclidean geometry of these features, existing Euclidean machineries cannot be directly used. In this paper, we tackle the classification tasks with limited training data on SPD manifolds. Our proposed framework, named Manifold Convex Class Model, represents each class on SPD manifolds using a convex model, and classification can be performed by computing distances to the convex models. We provide three methods based on different metrics to address the optimization problem of the smallest distance of a point to the convex model on SPD manifold. The efficacy of our proposed framework is demonstrated both on synthetic data and several computer vision tasks including object recognition, texture classification, person re-identification and traffic scene classification.},
	journal = {arXiv:1806.05343 [cs]},
	author = {Zhao, Kun and Wiliem, Arnold and Chen, Shaokang and Lovell, Brian C.},
	month = may,
	year = {2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\GregoireCattan\\Zotero\\storage\\T8TF6ZK4\\Zhao et al. - 2019 - Convex Class Model on Symmetric Positive Definite .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\GregoireCattan\\Zotero\\storage\\6PF2GE2V\\1806.html:text/html},
}

@techreport{gentinetta_complexity_2022,
	title = {The complexity of quantum support vector machines},
	url = {http://arxiv.org/abs/2203.00031},
	abstract = {Quantum support vector machines employ quantum circuits to define the kernel function. It has been shown that this approach offers a provable exponential speedup compared to any known classical algorithm for certain data sets. The training of such models corresponds to solving a convex optimization problem either via its primal or dual formulation. Due to the probabilistic nature of quantum mechanics, the training algorithms are affected by statistical uncertainty, which has a major impact on their complexity. We show that the dual problem can be solved in \${\textbackslash}mathcal\{O\}(M{\textasciicircum}\{4.67\}/{\textbackslash}varepsilon{\textasciicircum}2)\$ quantum circuit evaluations, where \$M\$ denotes the size of the data set and \${\textbackslash}varepsilon\$ the solution accuracy. We prove under an empirically motivated assumption that the kernelized primal problem can alternatively be solved in \${\textbackslash}mathcal\{O\}({\textbackslash}min {\textbackslash}\{ M{\textasciicircum}2/{\textbackslash}varepsilon{\textasciicircum}6, {\textbackslash}, 1/{\textbackslash}varepsilon{\textasciicircum}\{10\} {\textbackslash}\})\$ evaluations by employing a generalization of a known classical algorithm called Pegasos. Accompanying empirical results demonstrate these analytical complexities to be essentially tight. In addition, we investigate a variational approximation to quantum support vector machines and show that their heuristic training achieves considerably better scaling in our experiments.},
	number = {arXiv:2203.00031},
	urldate = {2022-05-20},
	institution = {arXiv},
	author = {Gentinetta, Gian and Thomsen, Arne and Sutter, David and Woerner, Stefan},
	month = feb,
	year = {2022},
	doi = {10.48550/arXiv.2203.00031},
	note = {arXiv:2203.00031 [quant-ph]
type: article},
	keywords = {Computer Science - Machine Learning, Quantum Physics},
	annote = {Comment: 24 pages, 13 figures},
	file = {arXiv Fulltext PDF:C\:\\Users\\GregoireCattan\\Zotero\\storage\\FEPH684W\\Gentinetta et al. - 2022 - The complexity of quantum support vector machines.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\GregoireCattan\\Zotero\\storage\\ULCMD94Q\\2203.html:text/html},
}

@article{rebentrost_quantum_2014,
	title = {Quantum {Support} {Vector} {Machine} for {Big} {Data} {Classification}},
	copyright = {Article is made available in accordance with the publisher's policy and may be subject to US copyright law. Please refer to the publisher's site for terms of use.},
	issn = {0031-9007},
	url = {https://dspace.mit.edu/handle/1721.1/90391},
	abstract = {Supervised machine learning is the classification of new data based on already classified training examples. In this work, we show that the support vector machine, an optimized binary classifier, can be implemented on a quantum computer, with complexity logarithmic in the size of the vectors and the number of training examples. In cases where classical sampling algorithms require polynomial time, an exponential speedup is obtained. At the core of this quantum big data algorithm is a nonsparse matrix exponentiation technique for efficiently performing a matrix inversion of the training data inner-product (kernel) matrix.},
	language = {en},
	urldate = {2022-05-26},
	journal = {American Physical Society},
	author = {Rebentrost, Patrick and Mohseni, Masoud and Lloyd, Seth},
	month = sep,
	year = {2014},
	note = {Accepted: 2014-09-26T14:53:32Z
Publisher: American Physical Society},
	file = {Full Text PDF:C\:\\Users\\GregoireCattan\\Zotero\\storage\\3AXFF23E\\Rebentrost et al. - 2014 - Quantum Support Vector Machine for Big Data Classi.pdf:application/pdf;Snapshot:C\:\\Users\\GregoireCattan\\Zotero\\storage\\9QGIRLIL\\90391.html:text/html},
}

@article{liu_rigorous_2021,
	title = {A rigorous and robust quantum speed-up in supervised machine learning},
	volume = {17},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1745-2481},
	url = {https://www.nature.com/articles/s41567-021-01287-z},
	doi = {10.1038/s41567-021-01287-z},
	abstract = {Recently, several quantum machine learning algorithms have been proposed that may offer quantum speed-ups over their classical counterparts. Most of these algorithms are either heuristic or assume that data can be accessed quantum-mechanically, making it unclear whether a quantum advantage can be proven without resorting to strong assumptions. Here we construct a classification problem with which we can rigorously show that heuristic quantum kernel methods can provide an end-to-end quantum speed-up with only classical access to data. To prove the quantum speed-up, we construct a family of datasets and show that no classical learner can classify the data inverse-polynomially better than random guessing, assuming the widely believed hardness of the discrete logarithm problem. Furthermore, we construct a family of parameterized unitary circuits, which can be efficiently implemented on a fault-tolerant quantum computer, and use them to map the data samples to a quantum feature space and estimate the kernel entries. The resulting quantum classifier achieves high accuracy and is robust against additive errors in the kernel entries that arise from finite sampling statistics.},
	language = {en},
	number = {9},
	urldate = {2022-05-26},
	journal = {Nature Physics},
	author = {Liu, Yunchao and Arunachalam, Srinivasan and Temme, Kristan},
	month = sep,
	year = {2021},
	note = {Number: 9
Publisher: Nature Publishing Group},
	keywords = {Computational science, Information theory and computation, Quantum information},
	pages = {1013--1017},
	file = {Snapshot:C\:\\Users\\GregoireCattan\\Zotero\\storage\\B5DCDWWP\\s41567-021-01287-z.html:text/html;Submitted Version:C\:\\Users\\GregoireCattan\\Zotero\\storage\\TUI75EQM\\Liu et al. - 2021 - A rigorous and robust quantum speed-up in supervis.pdf:application/pdf},
}

@inproceedings{cattan_first_2022,
	address = {Berlin, Germany},
	title = {First steps to the classification of {ERPs} using quantum computation},
	url = {https://hal.archives-ouvertes.fr/hal-03672246},
	abstract = {In this study, we investigate the performance of a quantum-enhanced support vector classifier for the binary classification of event-related potentials with electroencephalography. The resulting balanced accuracy on the training data was 83.17 \%, hence comparing with the results of prior arts. This suggests that QSVC is a promising technology for the classification of event-related potentials.},
	urldate = {2022-06-24},
	booktitle = {{NTB} {Berlin} 2022 - {International} {Forum} on {Neural} {Engineering} \& {Brain} {Technologies}},
	author = {Cattan, Grégoire and Andreev, Anton},
	month = may,
	year = {2022},
	keywords = {Interface cerveau-machine ICM, Electroencephalographie EEG, Machine learning, Quantum computing, Apprentissage supervise, Brain-computer interface BCI, Calcul quantique, Electroencephalograhy EEG, Event-related Potentials ERP, Potentiels Evoqués Cognitifs PEC},
	file = {HAL Snapshot:C\:\\Users\\GregoireCattan\\Zotero\\storage\\7KZ3A5E9\\hal-03672246.html:text/html},
}

@misc{grossi_mixed_2022,
	title = {Mixed {Quantum}-{Classical} {Method} {For} {Fraud} {Detection} with {Quantum} {Feature} {Selection}},
	url = {http://arxiv.org/abs/2208.07963},
	doi = {10.48550/arXiv.2208.07963},
	abstract = {This paper presents a first end-to-end application of a Quantum Support Vector Machine (QSVM) algorithm for a classification problem in the financial payment industry using the IBM Safer Payments and IBM Quantum Computers via the Qiskit software stack. Based on real card payment data, a thorough comparison is performed to assess the complementary impact brought in by the current state-of-the-art Quantum Machine Learning algorithms with respect to the Classical Approach. A new method to search for best features is explored using the Quantum Support Vector Machine's feature map characteristics. The results are compared using fraud specific key performance indicators: Accuracy, Recall, and False Positive Rate, extracted from analyses based on human expertise (rule decisions), classical machine learning algorithms (Random Forest, XGBoost) and quantum based machine learning algorithms using QSVM. In addition, a hybrid classical-quantum approach is explored by using an ensemble model that combines classical and quantum algorithms to better improve the fraud prevention decision. We found, as expected, that the results highly depend on feature selections and algorithms that are used to select them. The QSVM provides a complementary exploration of the feature space which led to an improved accuracy of the mixed quantum-classical method for fraud detection, on a drastically reduced data set to fit current state of Quantum Hardware.},
	urldate = {2022-08-19},
	publisher = {arXiv},
	author = {Grossi, Michele and Ibrahim, Noelle and Radescu, Voica and Loredo, Robert and Voigt, Kirsten and Von Altrock, Constantin and Rudnik, Andreas},
	month = aug,
	year = {2022},
	note = {arXiv:2208.07963 [quant-ph]},
	keywords = {Computer Science - Machine Learning, Quantum Physics},
	annote = {Comment: 11 pages, 12 figures, 9 tables},
	file = {arXiv Fulltext PDF:C\:\\Users\\GregoireCattan\\Zotero\\storage\\IYSFX6MA\\Grossi et al. - 2022 - Mixed Quantum-Classical Method For Fraud Detection.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\GregoireCattan\\Zotero\\storage\\GS94VR96\\2208.html:text/html},
}
